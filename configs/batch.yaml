{
  "model": [
    "NCA",
    # "GCN",
    # "MLP",
    # "FixedBfsNCA",
    # "BfsNCA",
  ],

  "n_layers": [
    # 4,
    # 8,
    # 16,
    # 32,
    64,
    # 96,
  ],

  # How often to calculate the loss.
  "loss_interval": [
    null,
    # 4,
    # 8,
    # 16,
    # 32,
    64,
  ],

  "n_hid_chan": [
    6,
    8,
    10,
    16,
    24,
    48,
    96,
    128,
    256,
  ],

  "shared_weights": [
    True,
    # False,
  ],

  "skip_connections": [
    True,
    # False,
  ],

  "cut_conv_corners": [
    True,
    # False,
  ],

  # Whether to enable the (bug/fix) that limits the gradients accumulated to the last few layers of the network. 
  # Presumably only valid when using shared weights for all layers. Faster, but (persumably) less stable.
  "sparse_update": [
    True,
    # False,
  ],

#   "minibatch_size": [
#     32,
#   ],

  "n_data": [
    # 256,
    # 512,
    # 1024,
    2048,
    # 4096,
    # 8192,
  ],

  "learning_rate": [
    # 0.0005,
    0.0001,
    # 0.00005,
    # 0.00001,
  ],

}